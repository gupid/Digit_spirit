{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b36d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "# 指定支持中文的字体，例如 'SimHei'\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "# 解决负号 '-' 显示为方块的问题\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b234bb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签分布情况:\n",
      " label\n",
      "1    1916\n",
      "3    1466\n",
      "2     649\n",
      "0     585\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 加载数据集\n",
    "df = pd.read_csv('system_log.csv')\n",
    "\n",
    "# --- 数据预处理 ---\n",
    "\n",
    "# 1. 将时间戳转换为datetime对象并排序\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "# 2. 识别数据采集的会话（Session）\n",
    "time_diff = df['timestamp'].diff()\n",
    "session_threshold = pd.Timedelta('1 minute')\n",
    "df['session_id'] = (time_diff > session_threshold).cumsum()\n",
    "\n",
    "# 3. 设置时间索引\n",
    "# 这是最核心的改动。让所有操作都基于一个显式的时间索引。\n",
    "df = df.set_index('timestamp')\n",
    "\n",
    "# 4. 在每个会话内部进行滑动窗口处理\n",
    "window_size = '10s' \n",
    "features_to_roll = [\n",
    "    'mouse_left_click',\n",
    "    'mouse_right_click',\n",
    "    'mouse_scroll',\n",
    "    'keyboard_counts',\n",
    "    'mouse_distance',\n",
    "    'bytes_sent_per_sec',\n",
    "    'bytes_recv_per_sec',\n",
    "    'packets_sent_per_sec',\n",
    "    'packets_recv_per_sec',\n",
    "    'read_bytes_per_sec',\n",
    "    'write_bytes_per_sec'\n",
    "]\n",
    "\n",
    "for col in features_to_roll:\n",
    "    new_col_name = f'{col}_freq'\n",
    "    # 现在我们按session_id分组，并在时间索引上直接进行滚动计算\n",
    "    # 注意，这里不再需要 on='timestamp' 参数，因为rolling操作默认就在索引上执行\n",
    "    rolled_series = df.groupby('session_id')[col].rolling(window=window_size).sum()\n",
    "    \n",
    "    # 结果的索引是 (session_id, timestamp)，我们需要去掉第一层session_id来对齐\n",
    "    df[new_col_name] = rolled_series.reset_index(level=0, drop=True)\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "# 6. 将时间戳转换为自第一个时间戳以来的总秒数\n",
    "df['timestamp'] = (df['timestamp'] - df['timestamp'].min()).dt.total_seconds()\n",
    "\n",
    "# 7. 对 'label' 列进行编码\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "print(\"标签分布情况:\\n\", df['label'].value_counts())\n",
    "num_classes = df['label'].nunique()\n",
    "\n",
    "# 9. 处理滑动窗口产生的NaN值（通常是每个会话最开始的几个点）\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# 保存处理后的数据\n",
    "df.to_csv('processed_system.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01451b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 数据集划分信息 ---\n",
      "训练集大小: 3150\n",
      "验证集大小: 0\n",
      "测试集大小: 1466\n",
      "--------------------\n",
      "总会话数: 5\n",
      "训练集会话ID数量: 4\n",
      "验证集会话ID数量: 0\n",
      "测试集会话ID数量: 1\n"
     ]
    }
   ],
   "source": [
    "# 分离特征 (X) 和目标 (y)\n",
    "features_to_drop = [\n",
    "    'label', 'timestamp', 'session_id',\n",
    "    'mouse_distance', 'mouse_left_click', 'mouse_right_click', 'mouse_scroll', 'keyboard_counts',\n",
    "    'bytes_sent_per_sec', 'bytes_recv_per_sec', 'packets_sent_per_sec',\n",
    "    'packets_recv_per_sec', 'read_bytes_per_sec', 'write_bytes_per_sec'\n",
    "]\n",
    "X = df.drop(features_to_drop, axis=1)\n",
    "y = df['label']\n",
    "\n",
    "print(\"用于训练的特征列信息:\")\n",
    "X.info()\n",
    "\n",
    "# 将数据拆分为训练集和测试集\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bc0946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. 执行基于会话分组的5折交叉验证 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\esp_robot_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "2 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\anaconda3\\envs\\esp_robot_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\anaconda3\\envs\\esp_robot_env\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\esp_robot_env\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1641, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [0 1 3]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\anaconda3\\envs\\esp_robot_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\anaconda3\\envs\\esp_robot_env\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda3\\envs\\esp_robot_env\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1641, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [1 2 3]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "e:\\anaconda3\\envs\\esp_robot_env\\Lib\\site-packages\\xgboost\\callback.py:264: UserWarning: [21:08:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:52: Empty dataset at worker: 0\n",
      "  score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交叉验证的每次准确率分数: [0.99154746 0.                nan        nan 0.98412698]\n",
      "交叉验证的平均准确率: nan (+/- nan)\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '-nan(ind)'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m交叉验证的每次准确率分数: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m交叉验证的平均准确率: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.mean(cv_scores)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (+/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.std(cv_scores)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# 在测试集上进行预测\u001b[39;00m\n\u001b[32m     23\u001b[39m y_pred = model.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda3\\envs\\esp_robot_env\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda3\\envs\\esp_robot_env\\Lib\\site-packages\\xgboost\\sklearn.py:1683\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1661\u001b[39m model, metric, params, feature_weights = \u001b[38;5;28mself\u001b[39m._configure_fit(\n\u001b[32m   1662\u001b[39m     xgb_model, params, feature_weights\n\u001b[32m   1663\u001b[39m )\n\u001b[32m   1664\u001b[39m train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[32m   1665\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1666\u001b[39m     X=X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1680\u001b[39m     feature_types=\u001b[38;5;28mself\u001b[39m.feature_types,\n\u001b[32m   1681\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1683\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1686\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1697\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1698\u001b[39m     \u001b[38;5;28mself\u001b[39m.objective = params[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda3\\envs\\esp_robot_env\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda3\\envs\\esp_robot_env\\Lib\\site-packages\\xgboost\\training.py:184\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    182\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    183\u001b[39m     bst.update(dtrain, iteration=i, fobj=obj)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[43m.\u001b[49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    185\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    187\u001b[39m bst = cb_container.after_training(bst)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda3\\envs\\esp_robot_env\\Lib\\site-packages\\xgboost\\callback.py:265\u001b[39m, in \u001b[36mCallbackContainer.after_iteration\u001b[39m\u001b[34m(self, model, epoch, dtrain, evals)\u001b[39m\n\u001b[32m    263\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m name.find(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m) == -\u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDataset name should not contain `-`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    264\u001b[39m     score: \u001b[38;5;28mstr\u001b[39m = model.eval_set(evals, epoch, \u001b[38;5;28mself\u001b[39m.metric, \u001b[38;5;28mself\u001b[39m._output_margin)\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     metric_score = \u001b[43m_parse_eval_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_history(metric_score, epoch)\n\u001b[32m    267\u001b[39m ret = \u001b[38;5;28many\u001b[39m(c.after_iteration(model, epoch, \u001b[38;5;28mself\u001b[39m.history) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda3\\envs\\esp_robot_env\\Lib\\site-packages\\xgboost\\core.py:134\u001b[39m, in \u001b[36m_parse_eval_str\u001b[39m\u001b[34m(result)\u001b[39m\n\u001b[32m    132\u001b[39m metric_score_str = [\u001b[38;5;28mtuple\u001b[39m(s.split(\u001b[33m\"\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m splited]\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# convert to float\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m metric_score = [(n, \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m n, s \u001b[38;5;129;01min\u001b[39;00m metric_score_str]\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m metric_score\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: '-nan(ind)'"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(\n",
    "    objective='multi:softprob',  # 明确指定为多分类任务\n",
    "    num_class=num_classes,       # 明确告知类别的数量\n",
    "    eval_metric='mlogloss'       \n",
    ")\n",
    "# 评估方法一: 5折交叉验证\n",
    "print(\"--- 1. 执行5折交叉验证 ---\")\n",
    "# 使用 cross_val_score 函数进行交叉验证，cv=5 表示5折\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"交叉验证的每次准确率分数: {cv_scores}\")\n",
    "print(f\"交叉验证的平均准确率: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\\n\")\n",
    "# 在训练集上训练模型，用于后续的评估\n",
    "model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c24fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. 分类报告 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      coding       1.00      1.00      1.00        52\n",
      "      gaming       1.00      1.00      1.00       193\n",
      "        idle       1.00      1.00      1.00        74\n",
      "       video       1.00      1.00      1.00       143\n",
      "\n",
      "    accuracy                           1.00       462\n",
      "   macro avg       1.00      1.00      1.00       462\n",
      "weighted avg       1.00      1.00      1.00       462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 评估方法二: 分类报告\n",
    "print(\"--- 2. 分类报告 ---\")\n",
    "# 获取原始的类别名称，用于报告显示\n",
    "target_names = label_encoder.classes_\n",
    "# 打印每个类别的精确率、召回率和F1分数\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f690e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3. 生成混淆矩阵图 (confusion_matrix.png) ---\n",
      "混淆矩阵图已保存。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 评估方法三: 混淆矩阵可视化\n",
    "print(\"--- 3. 生成混淆矩阵图 (confusion_matrix.png) ---\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.title('混淆矩阵 (Confusion Matrix)', fontsize=16)\n",
    "plt.ylabel('真实标签 (Actual Label)', fontsize=12)\n",
    "plt.xlabel('预测标签 (Predicted Label)', fontsize=12)\n",
    "# 保存图像到文件\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.close() # 关闭图像，防止显示混乱\n",
    "print(\"混淆矩阵图已保存。\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f39e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4. 生成特征重要性图 (feature_importance.png) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GUPID\\AppData\\Local\\Temp\\ipykernel_35972\\3862479974.py:9: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征重要性图已保存。\n",
      "\n",
      "所有评估已完成。\n"
     ]
    }
   ],
   "source": [
    "# 评估方法四: 特征重要性可视化\n",
    "print(\"--- 4. 生成特征重要性图 (feature_importance.png) ---\")\n",
    "feature_importances = model.feature_importances_\n",
    "features = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "# 按重要性得分降序排列\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')\n",
    "plt.title('特征重要性 (Feature Importance)', fontsize=16)\n",
    "plt.xlabel('重要性得分 (Importance Score)', fontsize=12)\n",
    "plt.ylabel('特征 (Features)', fontsize=12)\n",
    "plt.tight_layout() # 调整布局以防标签重叠\n",
    "# 保存图像到文件\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.close() # 关闭图像\n",
    "print(\"特征重要性图已保存。\\n\")\n",
    "\n",
    "print(\"所有评估已完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6bace1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存为 'xgboost_model.joblib'\n",
      "编码器已保存为 'label_encoder.joblib'\n"
     ]
    }
   ],
   "source": [
    "# 保存模型到文件\n",
    "joblib.dump(model, 'xgboost_model.joblib')\n",
    "\n",
    "# 保存 LabelEncoder 到文件\n",
    "joblib.dump(label_encoder, 'label_encoder.joblib')\n",
    "\n",
    "print(\"模型已保存为 'xgboost_model.joblib'\")\n",
    "print(\"编码器已保存为 'label_encoder.joblib'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0026d67d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esp_robot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
